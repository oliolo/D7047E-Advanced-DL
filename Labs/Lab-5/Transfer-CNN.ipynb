{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "trainset_MNIST_big = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainset_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000)))\n",
    "trainloader_MNIST = torch.utils.data.DataLoader(trainset_MNIST, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "val_set_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000, 20000)))\n",
    "val_loader_MNIST = torch.utils.data.DataLoader(val_set_MNIST, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testset_MNIST = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader_MNIST = torch.utils.data.DataLoader(testset_MNIST, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = models.resnet18(pretrained= False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_model = model\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        tr_correct = 0\n",
    "        tr_total = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
    "            \n",
    "            print(\"Epoch: \",epoch,\"Batch: \",batch_nr , end='\\r' )\n",
    "            # calculate prediction according to our model\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "            \n",
    "            # Backpropagate the loss through the network to find the gradients of all parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters along their gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clear stored gradient values\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    tr_correct+=1\n",
    "                tr_total +=1\n",
    "\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            \n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            if(loss < best_loss):\n",
    "                best_loss = loss\n",
    "                best_model = model\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    val_correct+=1\n",
    "                val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    tr_accuracy = tr_correct/tr_total\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Training accuracy:   {str(100*tr_accuracy)[:4]}%.')\n",
    "    print(f'Validation accuracy: {str(100*val_accuracy)[:4]}%.')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
    "        prediction = model.forward(data)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        for i in range(len(data)):    \n",
    "            guess = torch.argmax(prediction[i])\n",
    "            if(guess.item() == labels[i]):\n",
    "                val_correct+=1\n",
    "            val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Test accuracy: {str(100*val_accuracy)[:4]}%.', end='\\r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:   100.%.\n",
      "Validation accuracy: 96.2%.\n",
      "Test accuracy: 96.4%.\r"
     ]
    }
   ],
   "source": [
    "Trained_model = train(model, criterion, optimizer, trainloader_MNIST, val_loader_MNIST, num_epochs=10)\n",
    "test(Trained_model, testloader_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image - epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('NO GPU AVAILABLE ERROR')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2( model, test_loader, epsilon ):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        if target.item() == 4:\n",
    "            target = torch.tensor(9)\n",
    "            \n",
    "            # Send the data and label to the device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Set requires_grad attribute of tensor. Important for Attack\n",
    "            data.requires_grad = True\n",
    "\n",
    "            # Forward pass the data through the model\n",
    "            output = model(data)\n",
    "            init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "            # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "            if init_pred.item() != 4:\n",
    "                continue\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = F.nll_loss(output[0], target)\n",
    "\n",
    "            # Zero all existing gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Calculate gradients of model in backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Collect datagrad\n",
    "            data_grad = data.grad.data\n",
    "\n",
    "            # Call FGSM Attack\n",
    "            perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "            # Re-classify the perturbed image\n",
    "            output = model(perturbed_data)\n",
    "\n",
    "            # Check for success\n",
    "            final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            if final_pred.item() == target.item():\n",
    "                correct += 1\n",
    "                # Save some adv examples for visualization later\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "            total += 1\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/total\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, total, final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "epsilons = [.05, .1, .15, .2, .25, .3]\n",
    "\n",
    "test_loader_mnist = torch.utils.data.DataLoader(testset_MNIST,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False)\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test2(Trained_model, test_loader_mnist, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78d776e26a726845a150a952c27a68eddb22d28f3f64186fed14956ccdb93b0a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('D7047E_ADL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
