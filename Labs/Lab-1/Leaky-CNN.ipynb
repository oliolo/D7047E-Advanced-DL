{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%rm` not found.\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "%rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the dataset and insert it into relevent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the dataset\n",
    "def download():\n",
    "    (trainX, trainy), (testX, testy) = cifar10.load_data()\n",
    "    print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "    print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "\n",
    "    #one hot encode target values\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    \n",
    "    return trainX, trainy, testX, testy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the dataset in it's relevent way\n",
    "def prep_pixels(train, test):\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "\n",
    "    #normalize\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation=LeakyReLU(), input_shape=(32, 32, 3)))\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation=LeakyReLU()))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation=LeakyReLU()))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0001)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = download()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# define model\n",
    "\tmodel = define_model()\n",
    "\n",
    "\tlog_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\ttensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainY, epochs=100, batch_size=64, validation_data=(testX, testY), verbose=0, callbacks=[tensorboard_callback])\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(testX, testY)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\t# learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(50000, 32, 32, 3), y=(50000, 1)\n",
      "Test: X=(10000, 32, 32, 3), y=(10000, 1)\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0544s vs `on_train_batch_end` time: 1.1931s). Check your callbacks.\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 2.6882 - accuracy: 0.6474\n",
      "> 64.740\n"
     ]
    }
   ],
   "source": [
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5cfa8e1fd62d7eb8beb134597a3e6a4ed7d63db87a242cb567554c600c91ca9b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('anaconda_backup')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
