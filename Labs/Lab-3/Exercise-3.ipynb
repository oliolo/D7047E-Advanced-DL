{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "trainset_MNIST_big = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainset_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000)))\n",
    "trainloader_MNIST = torch.utils.data.DataLoader(trainset_MNIST, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "val_set_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000, 20000)))\n",
    "val_loader_MNIST = torch.utils.data.DataLoader(val_set_MNIST, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testset_MNIST = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader_MNIST = torch.utils.data.DataLoader(testset_MNIST, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = models.resnet18(pretrained= False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_model = model\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        tr_correct = 0\n",
    "        tr_total = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
    "            \n",
    "            print(\"Epoch: \",epoch,\"Batch: \",batch_nr)\n",
    "            # calculate prediction according to our model\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "            \n",
    "            # Backpropagate the loss through the network to find the gradients of all parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters along their gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clear stored gradient values\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    tr_correct+=1\n",
    "                tr_total +=1\n",
    "\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            \n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            if(loss < best_loss):\n",
    "                best_loss = loss\n",
    "                best_model = model\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    val_correct+=1\n",
    "                val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    tr_accuracy = tr_correct/tr_total\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Training accuracy:   {str(100*tr_accuracy)[:4]}%.')\n",
    "    print(f'Validation accuracy: {str(100*val_accuracy)[:4]}%.')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
    "        prediction = model.forward(data)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        for i in range(len(data)):    \n",
    "            guess = torch.argmax(prediction[i])\n",
    "            if(guess.item() == labels[i]):\n",
    "                val_correct+=1\n",
    "            val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Test accuracy: {str(100*val_accuracy)[:4]}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trained_model = train(model, criterion, optimizer, trainloader_MNIST, val_loader_MNIST, num_epochs=10)\n",
    "test(Trained_model, testloader_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trained_resnet_fe = Trained_model \n",
    "\n",
    "# FREEZE all old params\n",
    "for param in trained_resnet_fe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new layer\n",
    "num_ftrs = trained_resnet_fe.fc.in_features\n",
    "trained_resnet_fe.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# find the paramaters we want to update during training\n",
    "params_to_update = []\n",
    "for param in trained_resnet_fe.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
