{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "batch_size = 500\n",
    "\n",
    "trainset_MNIST_big = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainset_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000)))\n",
    "trainloader_MNIST = torch.utils.data.DataLoader(trainset_MNIST, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "val_set_MNIST = torch.utils.data.Subset(trainset_MNIST_big,list(range(10000, 20000)))\n",
    "val_loader_MNIST = torch.utils.data.DataLoader(val_set_MNIST, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "                                          \n",
    "testset_MNIST = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader_MNIST = torch.utils.data.DataLoader(testset_MNIST, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = models.resnet18(pretrained= False)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs):\n",
    "    best_model = model\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        tr_correct = 0\n",
    "        tr_total = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        for batch_nr, (data, labels) in enumerate(train_loader):\n",
    "            \n",
    "            print(\"Epoch: \",epoch,\"Batch: \",batch_nr)\n",
    "            # calculate prediction according to our model\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "            \n",
    "            # Backpropagate the loss through the network to find the gradients of all parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the parameters along their gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Clear stored gradient values\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    tr_correct+=1\n",
    "                tr_total +=1\n",
    "\n",
    "        for batch_nr, (data, labels) in enumerate(val_loader):\n",
    "            \n",
    "            prediction = model.forward(data)\n",
    "            \n",
    "            # Calculate the loss of the prediction by comparing to the expected output\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            if(loss < best_loss):\n",
    "                best_loss = loss\n",
    "                best_model = model\n",
    "\n",
    "            # calculate accuracy\n",
    "            for i in range(len(data)):    \n",
    "                guess = torch.argmax(prediction[i])\n",
    "                if(guess.item() == labels[i]):\n",
    "                    val_correct+=1\n",
    "                val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    tr_accuracy = tr_correct/tr_total\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Training accuracy:   {str(100*tr_accuracy)[:4]}%.')\n",
    "    print(f'Validation accuracy: {str(100*val_accuracy)[:4]}%.')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    for batch_nr, (data, labels) in enumerate(test_loader):\n",
    "        prediction = model.forward(data)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        for i in range(len(data)):    \n",
    "            guess = torch.argmax(prediction[i])\n",
    "            if(guess.item() == labels[i]):\n",
    "                val_correct+=1\n",
    "            val_total +=1\n",
    "\n",
    "    # primt accuracy\n",
    "    val_accuracy = val_correct/val_total\n",
    "    print(f'Test accuracy: {str(100*val_accuracy)[:4]}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch:  0\n",
      "Epoch:  0 Batch:  1\n",
      "Epoch:  0 Batch:  2\n",
      "Epoch:  0 Batch:  3\n",
      "Epoch:  0 Batch:  4\n",
      "Epoch:  0 Batch:  5\n",
      "Epoch:  0 Batch:  6\n",
      "Epoch:  0 Batch:  7\n",
      "Epoch:  0 Batch:  8\n",
      "Epoch:  0 Batch:  9\n",
      "Epoch:  0 Batch:  10\n",
      "Epoch:  0 Batch:  11\n",
      "Epoch:  0 Batch:  12\n",
      "Epoch:  0 Batch:  13\n",
      "Epoch:  0 Batch:  14\n",
      "Epoch:  0 Batch:  15\n",
      "Epoch:  0 Batch:  16\n",
      "Epoch:  0 Batch:  17\n",
      "Epoch:  0 Batch:  18\n",
      "Epoch:  0 Batch:  19\n",
      "Training accuracy:   0.44%.\n",
      "Validation accuracy: 0.62%.\n",
      "Test accuracy: 0.69%.\n"
     ]
    }
   ],
   "source": [
    "#Train CNN on MNIST for one epoch only.\n",
    "Trained_model = train(model, criterion, optimizer, trainloader_MNIST, val_loader_MNIST, num_epochs=1)\n",
    "test(Trained_model, testloader_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_resnet_fe = Trained_model \n",
    "\n",
    "# FREEZE all old params\n",
    "for param in trained_resnet_fe.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# new layer\n",
    "num_ftrs = trained_resnet_fe.fc.in_features\n",
    "trained_resnet_fe.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# find the paramaters we want to update during training\n",
    "params_to_update = []\n",
    "for param in trained_resnet_fe.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78d776e26a726845a150a952c27a68eddb22d28f3f64186fed14956ccdb93b0a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('D7047E_ADL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
